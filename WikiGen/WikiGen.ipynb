{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "WikiGen.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JThXsmC5iseP"
      },
      "source": [
        "##**WikiGen**\n",
        "####by Jason Ohanaga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-thIBC7a9Zh"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-29T21:21:34.930669Z",
          "iopub.execute_input": "2021-07-29T21:21:34.931006Z",
          "iopub.status.idle": "2021-07-29T21:21:34.937283Z",
          "shell.execute_reply.started": "2021-07-29T21:21:34.930977Z",
          "shell.execute_reply": "2021-07-29T21:21:34.936304Z"
        },
        "trusted": true,
        "id": "r7XuUVKOUpIu"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "!pip install wikipedia\n",
        "import wikipedia\n",
        "import re\n",
        "\n",
        "# necessary to use colab TPUs\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9plK4xUpIx"
      },
      "source": [
        "# Get text\n",
        "\n",
        "---\n",
        "\n",
        "Provide the topic and length of the text to be generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9XLxnYb6gbI",
        "outputId": "2b9e7f6d-7922-4fe9-9d9f-a392d86529f6"
      },
      "source": [
        "TOPIC = input(\"Input the topic: \")\n",
        "WORD_COUNT = int(input(\"Input the word count: \"))\n",
        "NUM_OF_TEXT = int(input(\"Input the number of text to be generated: \"))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input the topic: elvis presley\n",
            "Input the word count: 500\n",
            "Input the number of text to be generated: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5imQgGIUpIz"
      },
      "source": [
        "# Process the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "2knozkDPxLOJ",
        "outputId": "994732f6-2913-436b-8360-7851b375f6d8"
      },
      "source": [
        "wiki = wikipedia.page(TOPIC)\n",
        "text = wiki.content\n",
        "text = re.sub(r'==.*?==+', '', text)\n",
        "text = text.replace('\\n', '')\n",
        "text[:50]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Elvis Aaron Presley (January 8, 1935 â€“ August 16, '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-29T21:21:34.96735Z",
          "iopub.execute_input": "2021-07-29T21:21:34.967599Z",
          "iopub.status.idle": "2021-07-29T21:21:34.974043Z",
          "shell.execute_reply.started": "2021-07-29T21:21:34.967575Z",
          "shell.execute_reply": "2021-07-29T21:21:34.973066Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohCbiiZEUpIy",
        "outputId": "8af227ae-c101-481a-e630-c5d5a6813136"
      },
      "source": [
        "print(f'Length of text: {len(text)} characters')\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "print(f'Unique chars: {len(vocab)} ')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 115952 characters\n",
            "Unique chars: 83 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-29T21:21:35.069526Z",
          "iopub.execute_input": "2021-07-29T21:21:35.069899Z",
          "iopub.status.idle": "2021-07-29T21:21:35.101485Z",
          "shell.execute_reply.started": "2021-07-29T21:21:35.069862Z",
          "shell.execute_reply": "2021-07-29T21:21:35.099521Z"
        },
        "trusted": true,
        "id": "1soYSUBVUpI1"
      },
      "source": [
        "ids_from_chars = tf.keras.layers.experimental.preprocessing.StringLookup( # create ids from chars\n",
        "    vocabulary=list(vocab), mask_token=None, invert=False)\n",
        "\n",
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup( # create chars from ids\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "def text_from_ids(ids):\n",
        "    ''' Converts chars ids back to chars text sequence'''\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1) # convert id to char and add to back of list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhw-OcoHUpI2"
      },
      "source": [
        "# Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-29T21:21:35.103532Z",
          "iopub.execute_input": "2021-07-29T21:21:35.105072Z",
          "iopub.status.idle": "2021-07-29T21:21:35.944403Z",
          "shell.execute_reply.started": "2021-07-29T21:21:35.105023Z",
          "shell.execute_reply": "2021-07-29T21:21:35.943296Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2afz9hlUpI2",
        "outputId": "93105e10-c6a9-4d3c-b9eb-68c82137b365"
      },
      "source": [
        "# vectorize whole dataset\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "\n",
        "# creates a dataset from lists\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "for ids in ids_dataset.take(18):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'), end='')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elvis Aaron Presle"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-29T21:21:35.971909Z",
          "iopub.execute_input": "2021-07-29T21:21:35.972302Z",
          "iopub.status.idle": "2021-07-29T21:21:35.989638Z",
          "shell.execute_reply.started": "2021-07-29T21:21:35.972269Z",
          "shell.execute_reply": "2021-07-29T21:21:35.988824Z"
        },
        "trusted": true,
        "id": "eieLs7JbUpI3"
      },
      "source": [
        "# create sequences of length 100+1 | +1 is for that extra target char\n",
        "seq_length = 100\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-29T21:21:35.991308Z",
          "iopub.execute_input": "2021-07-29T21:21:35.991545Z",
          "iopub.status.idle": "2021-07-29T21:21:36.00246Z",
          "shell.execute_reply.started": "2021-07-29T21:21:35.991522Z",
          "shell.execute_reply": "2021-07-29T21:21:36.001071Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5aYCVqqUpI4",
        "outputId": "6742001f-9e73-4e88-9744-96a040d95859"
      },
      "source": [
        "# create input and label pairs\n",
        "def split_input_target(sequence):\n",
        "    ''' At each time step the input is the \n",
        "    current character and the label is the next character'''\n",
        "    \n",
        "    input = sequence[:-1]\n",
        "    target = sequence[1:]\n",
        "    return input, target\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input, label in dataset.take(1):\n",
        "    print(\"Input:\", text_from_ids(input).numpy())\n",
        "    print(\"Label:\", text_from_ids(label).numpy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: b'Elvis Aaron Presley (January 8, 1935 \\xe2\\x80\\x93 August 16, 1977), also known simply as Elvis, was an American'\n",
            "Label: b'lvis Aaron Presley (January 8, 1935 \\xe2\\x80\\x93 August 16, 1977), also known simply as Elvis, was an American '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-29T21:21:36.036205Z",
          "iopub.execute_input": "2021-07-29T21:21:36.036523Z",
          "iopub.status.idle": "2021-07-29T21:21:36.045467Z",
          "shell.execute_reply.started": "2021-07-29T21:21:36.03649Z",
          "shell.execute_reply": "2021-07-29T21:21:36.04447Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiN5eOo7UpI5",
        "outputId": "70974869-bbc4-4915-fa86-8da0c8510353"
      },
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "dataset"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((1024, 100), (1024, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC2AkA8QbhYg"
      },
      "source": [
        "# Config TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA_eQRZvFgRZ"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxAWQnLZUpI5"
      },
      "source": [
        "# Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-29T21:21:36.046978Z",
          "iopub.execute_input": "2021-07-29T21:21:36.047686Z",
          "iopub.status.idle": "2021-07-29T21:21:36.060174Z",
          "shell.execute_reply.started": "2021-07-29T21:21:36.047647Z",
          "shell.execute_reply": "2021-07-29T21:21:36.059025Z"
        },
        "trusted": true,
        "id": "9kcdo9f2UpI6"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embed_dimn, rnn_units, stateful=True):\n",
        "      super().__init__(self)\n",
        "      self.embed = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dimn)\n",
        "      self.gru = tf.keras.layers.GRU(rnn_units, stateful=stateful, return_sequences=True)\n",
        "      self.gru1 = tf.keras.layers.GRU(rnn_units, stateful=stateful, return_sequences=True)\n",
        "      self.dense = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "      x = self.embed(inputs)\n",
        "      x = self.gru(x)\n",
        "      x = self.gru1(x)\n",
        "      output = self.dense(x)\n",
        "      return output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aINDUP9NxxW"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESoMLw86MlKw"
      },
      "source": [
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "embed_dimn = 512\n",
        "rnn_units = 1024\n",
        "\n",
        "with strategy.scope():\n",
        "  model = MyModel(\n",
        "      vocab_size=vocab_size, \n",
        "      embed_dimn=embed_dimn, \n",
        "      rnn_units=rnn_units,\n",
        "      stateful=False,)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                metrics=['sparse_categorical_accuracy'])\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0I_9xUrUrYg",
        "outputId": "fcf3d188-cc85-4bdf-d309-30a6ad759a76"
      },
      "source": [
        "model.fit(\n",
        "    dataset,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)]\n",
        ")\n",
        "\n",
        "model.save_weights('./training_model.h5', overwrite=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 27s 108ms/step - loss: 2.8704 - sparse_categorical_accuracy: 0.2548\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.9000 - sparse_categorical_accuracy: 0.4575\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.2002 - sparse_categorical_accuracy: 0.6513\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4945 - sparse_categorical_accuracy: 0.8790\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1167 - sparse_categorical_accuracy: 0.9805\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9841\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9843\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0470 - sparse_categorical_accuracy: 0.9843\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0450 - sparse_categorical_accuracy: 0.9843\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0438 - sparse_categorical_accuracy: 0.9843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCEG3hJqN1hy"
      },
      "source": [
        "# Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM5jKQrxzoOC"
      },
      "source": [
        "def generate_text(content_txt, predict_len, batch_size):\n",
        "  # build model with appropriate shape based off of batch size\n",
        "  tf.keras.backend.clear_session()\n",
        "  pred_model = MyModel(\n",
        "      vocab_size=vocab_size, \n",
        "      embed_dimn=embed_dimn, \n",
        "      rnn_units=rnn_units,\n",
        "      stateful=True,)\n",
        "  pred_model.build(input_shape=[batch_size, None])\n",
        "  pred_model.load_weights('training_model.h5')\n",
        "\n",
        "  # preprocess initial content string\n",
        "  content = tf.strings.unicode_split(content_txt, 'UTF-8')\n",
        "  content = ids_from_chars(content).numpy()\n",
        "  content = np.repeat(np.expand_dims(content, 0), batch_size, axis=0)\n",
        "\n",
        "  # run the content forward to prime the state of model\n",
        "  pred_model.reset_states()\n",
        "  for i in range(len(content_txt) - 1):\n",
        "    pred_model.predict(content[:, i:i + 1])\n",
        "\n",
        "  # get predictions starting from last char of content string\n",
        "  predictions = [content[:, -1:]]\n",
        "  for i in range(predict_len):\n",
        "    last_word = predictions[-1]\n",
        "    next_probits = pred_model.predict(last_word)[:, 0, :] # pred.shape -> [batch size, seq len, vocab size]\n",
        "\n",
        "    # sample from our outputs probability distribution and add to predictions array\n",
        "    next_idx = [np.random.choice(vocab_size, p=next_probits[b]) for b in range(batch_size)]\n",
        "    predictions.append(np.array(next_idx, dtype=np.int32))\n",
        "\n",
        "  # convert predicted text ids back to chars and save\n",
        "  for b in range(batch_size):\n",
        "    p = np.array([predictions[j][b] for j in range(predict_len)], dtype=np.int32)\n",
        "    generate = content_txt[:-1]+text_from_ids(p).numpy().decode('utf-8')\n",
        "    \n",
        "    # save to file\n",
        "    path = \"generated_{0}_{1}.txt\".format(TOPIC.replace(' ', '_'), b+1)\n",
        "    f = open(path, \"w\")\n",
        "    f.write(generate)\n",
        "    f.close()\n",
        "    print(f'GENERATED TEXT {b+1}/{batch_size} Complete\\n\\n')\n",
        "\n",
        "  return\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Brq0YCnKY-S",
        "outputId": "ceb09133-8265-4416-abe0-d9615c31ae29"
      },
      "source": [
        "average_chars_per_word = 5\n",
        "content_txt = wiki.title\n",
        "predict_len = WORD_COUNT*average_chars_per_word - len(content_txt) # convert word count to average amount of chars\n",
        "\n",
        "generate_text(content_txt, predict_len, batch_size=NUM_OF_TEXT)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GENERATED TEXT 1/5 Complete\n",
            "\n",
            "\n",
            "GENERATED TEXT 2/5 Complete\n",
            "\n",
            "\n",
            "GENERATED TEXT 3/5 Complete\n",
            "\n",
            "\n",
            "GENERATED TEXT 4/5 Complete\n",
            "\n",
            "\n",
            "GENERATED TEXT 5/5 Complete\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}